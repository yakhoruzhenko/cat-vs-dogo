{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cat_vs_dog_0.0.2",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOglvtpeEkn7R5PoABINiJx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yarusx/cat-vs-dogo/blob/main/cat_vs_dog_0_0_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiRqay1L5Jpf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwPGT4J6rnQz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c16fd775-e1f0-4d60-d2dc-7fce562189cd"
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (160, 160)\n",
        "\n",
        "train_dataset = image_dataset_from_directory(train_dir,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "68608000/68606236 [==============================] - 1s 0us/step\n",
            "Found 2000 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX5lq12C5MK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "546d7592-442b-47db-fab1-3d612b171c22"
      },
      "source": [
        "validation_dataset = image_dataset_from_directory(validation_dir,\n",
        "                                                  shuffle=True,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  image_size=IMG_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1000 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2XPJ0Ow6PIh"
      },
      "source": [
        "class_names = train_dataset.class_names\n",
        "\n",
        "# plt.figure(figsize=(10, 10))\n",
        "# for images, labels in train_dataset.take(1):\n",
        "#   for i in range(9):\n",
        "#     ax = plt.subplot(3, 3, i + 1)\n",
        "#     plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "#     plt.title(class_names[labels[i]])\n",
        "#     plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27s1MeQEsF3k"
      },
      "source": [
        "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
        "test_dataset = validation_dataset.take(val_batches // 5)\n",
        "validation_dataset = validation_dataset.skip(val_batches // 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioJOG4uQsGQJ"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu-FPgdWsLHC"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT4BUW10sLbZ"
      },
      "source": [
        "# for image, _ in train_dataset.take(1):\n",
        "#   plt.figure(figsize=(10, 10))\n",
        "#   first_image = image[0]\n",
        "#   for i in range(9):\n",
        "#     ax = plt.subplot(3, 3, i + 1)\n",
        "#     augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
        "#     plt.imshow(augmented_image[0] / 255)\n",
        "#     plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfgnDgzHsLVr"
      },
      "source": [
        "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_iELV99sK4q",
        "outputId": "ef6a4bf3-7e9c-410c-a8fa-a9376fedd5e5"
      },
      "source": [
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRAHlTWcsiQm",
        "outputId": "d72ce125-e22f-49b2-9e10-5abe1b6d7461"
      },
      "source": [
        "image_batch, label_batch = next(iter(train_dataset))\n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 5, 5, 1280)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0p5nfLisiWx"
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp-_d-9Hsic5",
        "outputId": "6407ef9d-f739-4454-d25a-aafd8ad4501d"
      },
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(feature_batch_average.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 1280)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xeepjkysiT4",
        "outputId": "53fced44-4b15-4372-c282-f9fedc58802c"
      },
      "source": [
        "prediction_layer = tf.keras.layers.Dense(1)\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN5Bk-gJsiHR"
      },
      "source": [
        "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = rescale(x)\n",
        "x = base_model(x, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.4)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRqbxETRsvce"
      },
      "source": [
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7HD1M4IszrF",
        "outputId": "19b01417-8674-4028-c5d2-a156e888ec35"
      },
      "source": [
        "loss0, accuracy0 = model.evaluate(validation_dataset)\n",
        "print(\"initial loss: {:.2f}\".format(loss0))\n",
        "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26/26 [==============================] - 1s 45ms/step - loss: 0.6649 - accuracy: 0.5408\n",
            "initial loss: 0.66\n",
            "initial accuracy: 0.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1957R2ns63O",
        "outputId": "159d9905-80c3-4ce8-872c-49f5f671ae3c"
      },
      "source": [
        "initial_epochs = 1\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=validation_dataset)\n",
        "val_acc = history.history['val_accuracy']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 5s 77ms/step - loss: 0.6902 - accuracy: 0.6105 - val_loss: 0.4842 - val_accuracy: 0.6856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BCX_EaQ2s9E0",
        "outputId": "75030c37-141c-4e17-c4ff-b19aa248ba75"
      },
      "source": [
        "while np.mean(val_acc)*100 < 98.5:\n",
        "  initial_epochs = 3\n",
        "  history = model.fit(train_dataset,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=validation_dataset)\n",
        "  \n",
        "  val_acc = history.history['val_accuracy']\n",
        "  \n",
        "try:\n",
        "  !mkdir -p saved_model\n",
        "except:\n",
        "  pass\n",
        "\n",
        "model.save('saved_model/dvc/')\n",
        "\n",
        "!zip -r dvc.zip saved_model/dvc/\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"dvc.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1765 - accuracy: 0.9230 - val_loss: 0.0850 - val_accuracy: 0.9752\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.1732 - accuracy: 0.9235 - val_loss: 0.0831 - val_accuracy: 0.9765\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.1832 - accuracy: 0.9210 - val_loss: 0.0858 - val_accuracy: 0.9715\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.1874 - accuracy: 0.9150 - val_loss: 0.0790 - val_accuracy: 0.9790\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1710 - accuracy: 0.9310 - val_loss: 0.0793 - val_accuracy: 0.9777\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.1723 - accuracy: 0.9260 - val_loss: 0.0767 - val_accuracy: 0.9765\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.1757 - accuracy: 0.9245 - val_loss: 0.0798 - val_accuracy: 0.9765\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.1678 - accuracy: 0.9280 - val_loss: 0.0710 - val_accuracy: 0.9790\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 5s 72ms/step - loss: 0.1597 - accuracy: 0.9325 - val_loss: 0.0757 - val_accuracy: 0.9777\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 5s 72ms/step - loss: 0.1569 - accuracy: 0.9320 - val_loss: 0.0688 - val_accuracy: 0.9814\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 5s 72ms/step - loss: 0.1576 - accuracy: 0.9350 - val_loss: 0.0723 - val_accuracy: 0.9802\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.1667 - accuracy: 0.9315 - val_loss: 0.0694 - val_accuracy: 0.9802\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.1567 - accuracy: 0.9305 - val_loss: 0.0655 - val_accuracy: 0.9827\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.1526 - accuracy: 0.9330 - val_loss: 0.0641 - val_accuracy: 0.9839\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.1564 - accuracy: 0.9335 - val_loss: 0.0676 - val_accuracy: 0.9802\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.1537 - accuracy: 0.9300 - val_loss: 0.0669 - val_accuracy: 0.9802\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1556 - accuracy: 0.9285 - val_loss: 0.0694 - val_accuracy: 0.9802\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.1600 - accuracy: 0.9300 - val_loss: 0.0691 - val_accuracy: 0.9802\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.1506 - accuracy: 0.9335 - val_loss: 0.0622 - val_accuracy: 0.9827\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.1511 - accuracy: 0.9305 - val_loss: 0.0622 - val_accuracy: 0.9827\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1444 - accuracy: 0.9420 - val_loss: 0.0586 - val_accuracy: 0.9827\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.1524 - accuracy: 0.9385 - val_loss: 0.0641 - val_accuracy: 0.9814\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.1547 - accuracy: 0.9335 - val_loss: 0.0584 - val_accuracy: 0.9839\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.1479 - accuracy: 0.9405 - val_loss: 0.0653 - val_accuracy: 0.9802\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1475 - accuracy: 0.9415 - val_loss: 0.0600 - val_accuracy: 0.9814\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1344 - accuracy: 0.9510 - val_loss: 0.0563 - val_accuracy: 0.9864\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.1363 - accuracy: 0.9450 - val_loss: 0.0627 - val_accuracy: 0.9814\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.1341 - accuracy: 0.9450 - val_loss: 0.0570 - val_accuracy: 0.9839\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1428 - accuracy: 0.9345 - val_loss: 0.0603 - val_accuracy: 0.9802\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1259 - accuracy: 0.9470 - val_loss: 0.0565 - val_accuracy: 0.9827\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.1578 - accuracy: 0.9295 - val_loss: 0.0596 - val_accuracy: 0.9814\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1392 - accuracy: 0.9370 - val_loss: 0.0549 - val_accuracy: 0.9827\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.1464 - accuracy: 0.9365 - val_loss: 0.0579 - val_accuracy: 0.9839\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1479 - accuracy: 0.9385 - val_loss: 0.0597 - val_accuracy: 0.9814\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.1339 - accuracy: 0.9395 - val_loss: 0.0529 - val_accuracy: 0.9839\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1478 - accuracy: 0.9400 - val_loss: 0.0601 - val_accuracy: 0.9790\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 5s 80ms/step - loss: 0.1355 - accuracy: 0.9450 - val_loss: 0.0556 - val_accuracy: 0.9814\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.1335 - accuracy: 0.9425 - val_loss: 0.0576 - val_accuracy: 0.9814\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1315 - accuracy: 0.9435 - val_loss: 0.0591 - val_accuracy: 0.9827\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.1465 - accuracy: 0.9415 - val_loss: 0.0561 - val_accuracy: 0.9839\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1251 - accuracy: 0.9520 - val_loss: 0.0584 - val_accuracy: 0.9790\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1364 - accuracy: 0.9460 - val_loss: 0.0501 - val_accuracy: 0.9851\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.1365 - accuracy: 0.9360 - val_loss: 0.0514 - val_accuracy: 0.9839\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1302 - accuracy: 0.9435 - val_loss: 0.0538 - val_accuracy: 0.9839\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1406 - accuracy: 0.9385 - val_loss: 0.0551 - val_accuracy: 0.9839\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.1400 - accuracy: 0.9360 - val_loss: 0.0551 - val_accuracy: 0.9827\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.1442 - accuracy: 0.9380 - val_loss: 0.0517 - val_accuracy: 0.9839\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1339 - accuracy: 0.9465 - val_loss: 0.0550 - val_accuracy: 0.9839\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.1499 - accuracy: 0.9345 - val_loss: 0.0568 - val_accuracy: 0.9814\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1401 - accuracy: 0.9435 - val_loss: 0.0527 - val_accuracy: 0.9839\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.1285 - accuracy: 0.9410 - val_loss: 0.0575 - val_accuracy: 0.9827\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1457 - accuracy: 0.9355 - val_loss: 0.0564 - val_accuracy: 0.9839\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1210 - accuracy: 0.9520 - val_loss: 0.0491 - val_accuracy: 0.9876\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.1300 - accuracy: 0.9450 - val_loss: 0.0513 - val_accuracy: 0.9851\n",
            "INFO:tensorflow:Assets written to: saved_model/dvc/assets\n",
            "updating: saved_model/dvc/ (stored 0%)\n",
            "updating: saved_model/dvc/assets/ (stored 0%)\n",
            "updating: saved_model/dvc/variables/ (stored 0%)\n",
            "updating: saved_model/dvc/variables/variables.index (deflated 75%)\n",
            "updating: saved_model/dvc/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "updating: saved_model/dvc/saved_model.pb (deflated 92%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_8b1e9580-59b3-400a-83fb-5b6df099ca0d\", \"dvc.zip\", 8737427)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmwn3pu_Slqg",
        "outputId": "54c616a1-f71b-4a60-8cee-b215ecd21f5f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip -q /content/drive/MyDrive/dvc.zip\n",
        "dvc = tf.keras.models.load_model('/content/saved_model/dvc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "replace saved_model/dvc/variables/variables.index? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRqnvxzUS0qB"
      },
      "source": [
        "try:\n",
        "  !mkdir -p saved_model\n",
        "except:\n",
        "  pass\n",
        "\n",
        "model.save('saved_model/dvc/')\n",
        "\n",
        "!zip -r dvc.zip saved_model/dvc/\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"dvc.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SST4JgPYCQo6"
      },
      "source": [
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# load and prepare the image\n",
        "def load_image(filename):\n",
        "\t# load the image\n",
        "\timg = load_img(filename, target_size=(160, 160))\n",
        "\t# convert to array\n",
        "\timg = img_to_array(img)\n",
        "\t# reshape into a single sample with 3 channels\n",
        "\timg = img.reshape(1, 160, 160, 3)\n",
        "\treturn img\n",
        "\n",
        "img = load_image('/content/drive/MyDrive/dayana_1.JPG')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yB7iawifYUQ"
      },
      "source": [
        "categories = [\"Cat\", \"Dog\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNwRlmT_giR_"
      },
      "source": [
        "prediction = dvc_model.predict(img)\n",
        "prediction = tf.nn.sigmoid(prediction)\n",
        "print(prediction)\n",
        "plt.figure()\n",
        "plt.imshow(img[0]/255)\n",
        "plt.title(categories[int(np.round_(prediction))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHy6nmep_9zy",
        "outputId": "9b5f0e9e-eed7-4f7e-f467-e844cef1d21f"
      },
      "source": [
        "loss0, accuracy0 = model.evaluate(validation_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26/26 [==============================] - 1s 40ms/step - loss: 0.0848 - accuracy: 0.9765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvGVe1R0RzNH"
      },
      "source": [
        "# #Retrieve a batch of images from the test set\n",
        "# image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
        "# predictions = model.predict_on_batch(image_batch).flatten()\n",
        "\n",
        "# # Apply a sigmoid since our model returns logits\n",
        "# predictions = tf.nn.sigmoid(predictions)\n",
        "# predictions = tf.where(predictions < 0.5, 0, 1)\n",
        "\n",
        "# print('Predictions:\\n', predictions.numpy())\n",
        "# print('Labels:\\n', label_batch)\n",
        "\n",
        "# plt.figure(figsize=(10, 10))\n",
        "# for i in range(9):\n",
        "#   ax = plt.subplot(3, 3, i + 1)\n",
        "#   plt.imshow(image_batch[i].astype(\"uint8\"))\n",
        "#   plt.title(class_names[predictions[i]])\n",
        "#   plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}